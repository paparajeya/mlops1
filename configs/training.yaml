# Training Configuration
model:
  name: "mnist_cnn"
  architecture: "cnn"
  input_size: [28, 28]
  num_classes: 10
  dropout_rate: 0.2

training:
  batch_size: 64
  learning_rate: 0.001
  epochs: 10
  optimizer: "adam"
  loss_function: "cross_entropy"
  scheduler: "step"
  scheduler_step_size: 7
  scheduler_gamma: 0.1

data:
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  data_dir: "data/processed"
  augmentations:
    rotation: 10
    horizontal_flip: false
    vertical_flip: false
    brightness: 0.1
    contrast: 0.1

experiment:
  name: "mnist_classification"
  tracking_uri: "http://localhost:5000"
  log_artifacts: true
  log_metrics: true

evaluation:
  metrics: ["accuracy", "precision", "recall", "f1"]
  save_predictions: true
  confusion_matrix: true

validation:
  threshold_accuracy: 0.95
  threshold_loss: 0.1
  early_stopping_patience: 5 